## ----global_options-----------------------------------------------------------
#| include: false
library(robustbase)
library(np)
options(np.tree=TRUE,np.messages=FALSE)
M <- 1000


## ----categoricalkernel--------------------------------------------------------
#| out.width = "75%"
set.seed(42)
n <- 100
X <- sort(rbinom(n,5,.3))
dgp <- sin(2.5*X)
Y <- dgp + rnorm(n,sd=sd(dgp))
plot(X,Y,cex=.5,col="grey")
ghat.dgp <- lm(Y~sin(2.5*X))
points(X,fitted(ghat.dgp),col=2)
ghat.nw <- npreg(Y~ordered(X),bwtype="fixed",ckertype="epanechnikov")
points(X,fitted(ghat.nw),col=3)
points(X,dgp,col=4)
legend("topleft",c("Oracle","NP","DGP"),pch=1,col=2:4,bty="n")


## ----continuouskernel---------------------------------------------------------
#| out.width = "75%"
set.seed(42)    
n <- 100
X <- sort(runif(n))
dgp <- rep(1,n)
Y <- dgp + rnorm(n)
plot(X,Y,cex=.5,col="grey")
ghat.dgp <- lm(Y~1)
points(X,fitted(ghat.dgp),col=2)
ghat.nw <- npreg(Y~X,bwtype="fixed",ckertype="epanechnikov")
points(X,fitted(ghat.nw),col=3)
points(X,dgp,col=4)
legend("topleft",c("Oracle","NP","DGP"),pch=1,col=2:4,bty="n")


## ----ordered------------------------------------------------------------------
## Write a monte carlo simulation that compute the pointwise RMSE of the fitted
## values generated by npreg() using the newdata evaluation points
set.seed(42)

n.trials <- 2
n.vec <- c(50,100,200,400,800,1600,3200)
X.pred.dgp <- X.pred <- 0:2
X.pred <- ordered(X.pred)
dgp.pred <- sin(2.5*X.pred.dgp)
newdata.dgp <- data.frame(X=X.pred.dgp)
newdata <- data.frame(X=X.pred)

fitted.array.dgp <- array(NA,dim=c(length(n.vec),M,length(X.pred)))
fitted.array <- array(NA,dim=c(length(n.vec),M,length(X.pred)))

for(j in 1:length(n.vec)) {
  for(i in 1:M) {
    X <- rbinom(n.vec[j],n.trials,.5)
    dgp <- sin(2.5*X)
    Y <- dgp + rnorm(n.vec[j],sd=sd(dgp))
    ghat.dgp <- lm(Y~sin(2.5*X))
    fitted.array.dgp[j,i,] <- predict(ghat.dgp,newdata=newdata.dgp)
    ghat.nw <- npreg(Y~ordered(X,levels=0:n.trials))
    fitted.array[j,i,] <- predict(ghat.nw,newdata=newdata)
  }
}

## Compute pointwise RMSE at each support point

rmse.dgp <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
rmse <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))

for(j in 1:length(n.vec)) {
  rmse.dgp[j,] <- sqrt(colMeans(sweep(fitted.array.dgp[j,,],2,dgp.pred)^2))
  rmse[j,] <- sqrt(colMeans(sweep(fitted.array[j,,],2,dgp.pred)^2))
}

rmse.dgp.pointwise <- numeric()
rmse.pointwise <- numeric()

for(i in 1:length(X.pred)) {
  rmse.dgp.pointwise[i] <- coef(ltsReg(log(rmse.dgp[,i])~log(n.vec)))[2]
  rmse.pointwise[i] <- coef(ltsReg(log(rmse[,i])~log(n.vec)))[2]
}
foo.ot <- data.frame(X.pred,rmse.dgp.pointwise,rmse.pointwise,rmse.pointwise/rmse.dgp.pointwise)
colnames(foo.ot) <- c("X","Oracle","NW","ratio")


## ----orderedtable-------------------------------------------------------------
knitr::kable(foo.ot,digits=2,align="rlll")


## ----bierens------------------------------------------------------------------
## Write a monte carlo simulation that compute the pointwise RMSE of the fitted
## values generated by npreg() using the newdata evaluation points
set.seed(42)

n.trials <- 2
n.vec <- c(50,100,200,400,800,1600,3200)
X.pred.dgp <- X.pred <- 0:2
X.pred <- X.pred
dgp.pred <- sin(2.5*X.pred.dgp)
newdata.dgp <- data.frame(X=X.pred.dgp)
newdata <- data.frame(X=X.pred)

fitted.array.dgp <- array(NA,dim=c(length(n.vec),M,length(X.pred)))
fitted.array <- array(NA,dim=c(length(n.vec),M,length(X.pred)))

for(j in 1:length(n.vec)) {
  for(i in 1:M) {
    X <- rbinom(n.vec[j],n.trials,.5)
    dgp <- sin(2.5*X)
    Y <- dgp + rnorm(n.vec[j],sd=sd(dgp))
    ghat.dgp <- lm(Y~sin(2.5*X))
    fitted.array.dgp[j,i,] <- predict(ghat.dgp,newdata=newdata.dgp)
    ghat.nw <- npreg(Y~X,ckertype="epanechnikov")
    fitted.array[j,i,] <- predict(ghat.nw,newdata=newdata)
  }
}

## Compute pointwise RMSE at each support point

rmse.dgp <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
rmse <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))

for(j in 1:length(n.vec)) {
  rmse.dgp[j,] <- sqrt(colMeans(sweep(fitted.array.dgp[j,,],2,dgp.pred)^2))
  rmse[j,] <- sqrt(colMeans(sweep(fitted.array[j,,],2,dgp.pred)^2))
}

rmse.dgp.pointwise <- numeric()
rmse.pointwise <- numeric()

for(i in 1:length(X.pred)) {
  rmse.dgp.pointwise[i] <- coef(ltsReg(log(rmse.dgp[,i])~log(n.vec)))[2]
  rmse.pointwise[i] <- coef(ltsReg(log(rmse[,i])~log(n.vec)))[2]
}
foo.bt <- data.frame(X.pred,rmse.dgp.pointwise,rmse.pointwise,rmse.pointwise/rmse.dgp.pointwise)
colnames(foo.bt) <- c("X","Oracle","NW","ratio")


## ----bierenstable-------------------------------------------------------------
knitr::kable(foo.bt,digits=2,align="rlll")


## ----irrelevant---------------------------------------------------------------
## Write a monte carlo simulation that compute the pointwise RMSE of the fitted
## values generated by npreg() using the newdata evaluation points
## X.pred = c(-2,0,2) for a sample size of n = 50, 100, 200, 400, 800.
set.seed(42)

n.vec <- c(50,100,200,400,800,1600)
X.pred.dgp <- X.pred <- c(-2,0,2)
X.pred <- X.pred
dgp.pred <- rep(0,length(X.pred))
newdata.dgp <- data.frame(X=X.pred.dgp)
newdata <- data.frame(X=X.pred)

fitted.array.dgp <- array(NA,dim=c(length(n.vec),M,length(X.pred)))
fitted.array <- array(NA,dim=c(length(n.vec),M,length(X.pred)))

for(j in 1:length(n.vec)) {
  for(i in 1:M) {
    X <- runif(n.vec[j],min=-3,max=3)
    dgp <- rep(0,length=n.vec[j])
    Y <- dgp + rnorm(n.vec[j],sd=.1)
    ghat.dgp <- lm(Y~1)
    fitted.array.dgp[j,i,] <- predict(ghat.dgp,newdata=newdata.dgp)
    ghat.nw <- npreg(Y~X,ckertype="epanechnikov")
    fitted.array[j,i,] <- predict(ghat.nw,newdata=newdata)
  }
}

## Compute pointwise RMSE at each support point

rmse.dgp <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
rmse <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
for(j in 1:length(n.vec)) {
  rmse.dgp[j,] <- sqrt(colMeans(sweep(fitted.array.dgp[j,,],2,dgp.pred)^2))
  rmse[j,] <- sqrt(colMeans(sweep(fitted.array[j,,],2,dgp.pred)^2))
}

rmse.dgp.pointwise <- numeric()
rmse.pointwise <- numeric()

for(i in 1:length(X.pred)) {
  rmse.dgp.pointwise[i] <- coef(ltsReg(log(rmse.dgp[,i])~log(n.vec)))[2]
  rmse.pointwise[i] <- coef(ltsReg(log(rmse[,i])~log(n.vec)))[2]
}
foo.it <- data.frame(X.pred,rmse.dgp.pointwise,rmse.pointwise,rmse.pointwise/rmse.dgp.pointwise)
colnames(foo.it) <- c("X","Oracle","NW","ratio")


## ----irrelevanttable----------------------------------------------------------
knitr::kable(foo.it,digits=2,align="rlll")


## ----continuous---------------------------------------------------------------
## Write a monte carlo simulation that compute the pointwise RMSE of the fitted
## values generated by npreg() using the newdata evaluation points
## X.pred = c(-2,0,2) for a sample size of n = 50, 100, 200, 400, 800.
set.seed(42)

n.vec <- c(100,200,400,800,1600,3200,6400,12800)
X.pred.dgp <- X.pred <- c(-2,0,2)
X.pred <- X.pred
dgp.pred <- sin(2.5*X.pred.dgp)
newdata.dgp <- data.frame(X=X.pred.dgp)
newdata <- data.frame(X=X.pred)

fitted.array.dgp <- array(NA,dim=c(length(n.vec),M,length(X.pred)))
fitted.array <- array(NA,dim=c(length(n.vec),M,length(X.pred)))

for(j in 1:length(n.vec)) {
  for(i in 1:M) {
    X <- runif(n.vec[j],min=-3,max=3)
    dgp <- sin(2.5*X)
    Y <- dgp + rnorm(n.vec[j],sd=sd(dgp))
    ghat.dgp <- lm(Y~sin(2.5*X))
    fitted.array.dgp[j,i,] <- predict(ghat.dgp,newdata=newdata.dgp)
    ghat.nw <- npreg(Y~X,ckertype="epanechnikov")
    fitted.array[j,i,] <- predict(ghat.nw,newdata=newdata)
  }
}

## Compute pointwise RMSE at each support point

rmse.dgp <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
rmse <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
for(j in 1:length(n.vec)) {
  rmse.dgp[j,] <- sqrt(colMeans(sweep(fitted.array.dgp[j,,],2,dgp.pred)^2))
  rmse[j,] <- sqrt(colMeans(sweep(fitted.array[j,,],2,dgp.pred)^2))
}

rmse.dgp.pointwise <- numeric()
rmse.pointwise <- numeric()

for(i in 1:length(X.pred)) {
  rmse.dgp.pointwise[i] <- coef(ltsReg(log(rmse.dgp[,i])~log(n.vec)))[2]
  rmse.pointwise[i] <- coef(ltsReg(log(rmse[,i])~log(n.vec)))[2]
}
foo.ct <- data.frame(X.pred,rmse.dgp.pointwise,rmse.pointwise,rmse.pointwise/rmse.dgp.pointwise)
colnames(foo.ct) <- c("X","Oracle","NW","ratio")


## ----continuoustable----------------------------------------------------------
knitr::kable(foo.ct,digits=2,align="rlll")


## ----claw---------------------------------------------------------------------
#| fig.asp=0.75
library(np)
library(robustbase)
options(np.tree=TRUE,np.messages=FALSE)
set.seed(42)

fx <- function(x) {
  0.5*dnorm(x+.767)+3*dnorm((x+.767-0.8)/.1)+2*dnorm((x+.767-1.2)/.1) 
}

fxmsd <- function(x) {
  0.5*dnorm(x,mean=-.767)+3*.1*dnorm(x,mean=-(.767-0.8),sd=.1)+2*.1*dnorm(x,mean=-(.767-1.2),sd=.1) 
}

rfxmsd <- function(n) {
  P <- sample(c("A","B","C"),n,replace=TRUE,prob=c(0.5,0.3,0.2))
  P.n <- numeric(n)
  P.n[P=="A"] <- rnorm(length(P[P=="A"]),mean=-.767)
  P.n[P=="B"] <- rnorm(length(P[P=="B"]),mean=-(.767-0.8),sd=.1)
  P.n[P=="C"] <- rnorm(length(P[P=="C"]),mean=-(.767-1.2),sd=.1) 
  return(P.n)
}

x <- seq(-3.5,2,length=1000)

par(mfrow=c(2,2))

n <- 10^4
breaks <- 100

X <- sort(rfxmsd(n))
xlim <- c(-3.5,2)
ylim <- range(hist(X,breaks=breaks,plot=FALSE)$density,fxmsd(x))

plot(x,fx(x),main="Density",xlim=xlim,xlab="X",ylab="fx(x)",type="l")
lines(x,fxmsd(x),lty=2,col=2)
abline(v=c(-.767,-(.767-0.8),-(.767-1.2)),col=2,lty=2)

hist(X,xlim=xlim,ylim=ylim,breaks=breaks,prob=TRUE,
     main="Histogram/Density",
     sub="Random Draw from fx(x)")
lines(x,fxmsd(x))
abline(v=c(-.767,-(.767-0.8),-(.767-1.2)),col=2,lty=2)

dgp <- sin(2.5*X)
Y <- dgp + rnorm(n,sd=sd(dgp))
plot(X,Y,cex=.1,xlim=xlim,col="grey")
ghat.dgp <- lm(Y~sin(2.5*X))
lines(X,fitted(ghat.dgp),col=2,lwd=2)
ghat.nw <- npreg(Y~X,bwtype="fixed",ckertype="epanechnikov")
lines(X,fitted(ghat.nw),col=3,lwd=3)
abline(v=c(-.767,-(.767-0.8),-(.767-1.2)),col=2,lty=2)
legend("topleft",c("Oracle","NW"),col=c(2,3),lwd=c(2,3),bty="n")

## Monte Carlo

n.vec <- c(50,100,200,400,800,1600,3200,6400,12800)
X.pred.dgp <- X.pred <- c(-.767,-(.767-0.8),-(.767-1.2))
X.pred <- X.pred
dgp.pred <- sin(2.5*X.pred.dgp)
newdata.dgp <- data.frame(X=X.pred.dgp)
newdata <- data.frame(X=X.pred)

fitted.array.dgp <- array(NA,dim=c(length(n.vec),M,length(X.pred)))
fitted.array <- array(NA,dim=c(length(n.vec),M,length(X.pred)))

for(j in 1:length(n.vec)) {
  for(i in 1:M) {
    X <- rfxmsd(n.vec[j])
    dgp <- sin(2.5*X)
    Y <- dgp + rnorm(n.vec[j],sd=sd(dgp))
    ghat.dgp <- lm(Y~sin(2.5*X))
    fitted.array.dgp[j,i,] <- predict(ghat.dgp,newdata=newdata.dgp)
    ghat.nw <- npreg(Y~X,ckertype="epanechnikov")
    fitted.array[j,i,] <- predict(ghat.nw,newdata=newdata)
  }
}

## Compute pointwise RMSE at each support point

rmse.dgp <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
rmse <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
for(j in 1:length(n.vec)) {
  rmse.dgp[j,] <- sqrt(colMeans(sweep(fitted.array.dgp[j,,],2,dgp.pred)^2))
  rmse[j,] <- sqrt(colMeans(sweep(fitted.array[j,,],2,dgp.pred)^2))
}

rmse.dgp.pointwise <- numeric()
rmse.pointwise <- numeric()

for(i in 1:length(X.pred)) {
  rmse.dgp.pointwise[i] <- coef(ltsReg(log(rmse.dgp[,i])~log(n.vec)))[2]
  rmse.pointwise[i] <- coef(ltsReg(log(rmse[,i])~log(n.vec)))[2]
}

ylim <- range(c(rmse.dgp.pointwise,rmse.pointwise))

plot(X.pred.dgp,rmse.dgp.pointwise,main="Rate of Convergence",xlim=xlim,ylim=ylim,xlab="X",ylab="RMSE",type="b")
lines(X.pred.dgp,rmse.pointwise,xlab="X",ylab="RMSE",type="b",col="red")
abline(v=c(-.767,-(.767-0.8),-(.767-1.2)),col=2,lty=2)
legend("topleft",legend=c("Oracle","NW"),col=c("black","red"),lty=1,bty="n")

foo.claw <- data.frame(X.pred,rmse.dgp.pointwise,rmse.pointwise,rmse.pointwise/rmse.dgp.pointwise)
colnames(foo.claw) <- c("X","Oracle","NW","ratio")


## ----clawtable----------------------------------------------------------------
knitr::kable(foo.claw,digits=2,align="rlll")


## ----illustrative,echo=TRUE,eval=FALSE----------------------------------------
## ## Monte Carlo reps, vector of n, vector of X.pred
## M <- 1000
## n.vec <- c(50,100,200,400,800,1600,3200,6400,12800)
## X.pred <- c(-.767,-(.767-0.8),-(.767-1.2))
## ## Prediction data frame
## newdata <- data.frame(X=X.pred)
## ## Storage arrays
## fitted.array.dgp <- array(NA,dim=c(length(n.vec),M,length(X.pred)))
## fitted.array <- array(NA,dim=c(length(n.vec),M,length(X.pred)))
## ## Monte Carlo
## for(j in 1:length(n.vec)) {
##   for(i in 1:M) {
##     X <- rfxmsd(n.vec[j])
##     dgp <- sin(2.5*X)
##     Y <- dgp + rnorm(n.vec[j],sd=sd(dgp))
##     ghat.dgp <- lm(Y~sin(2.5*X))
##     fitted.array.dgp[j,i,] <- predict(ghat.dgp,newdata=newdata)
##     ghat.nw <- npreg(Y~X,ckertype="epanechnikov")
##     fitted.array[j,i,] <- predict(ghat.nw,newdata=newdata)
##   }
## }
## ## Compute pointwise RMSE at each support point for each n
## rmse.dgp <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
## rmse <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
## for(j in 1:length(n.vec)) {
##   rmse.dgp[j,] <- sqrt(colMeans(sweep(fitted.array.dgp[j,,],2,dgp.pred)^2))
##   rmse[j,] <- sqrt(colMeans(sweep(fitted.array[j,,],2,dgp.pred)^2))
## }
## ## Compute RMSE rate
## rmse.dgp.pointwise <- numeric()
## rmse.pointwise <- numeric()
## for(i in 1:length(X.pred)) {
##   rmse.dgp.pointwise[i] <- coef(ltsReg(log(rmse.dgp[,i])~log(n.vec)))[2]
##   rmse.pointwise[i] <- coef(ltsReg(log(rmse[,i])~log(n.vec)))[2]
## }
## 

