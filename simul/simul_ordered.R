## Write a monte carlo simulation that compute the pointwise MSE of the fitted
## values generated by npreg() using the newdata evaluation points
rm(list=ls())
library(robustbase)
library(np)
options(np.tree=TRUE,np.messages=FALSE)

M <- 1000
n.trials <- 2
n.vec <- c(50,100,200,400,800,1600,3200)
X.pred.dgp <- X.pred <- 0:2
X.pred <- ordered(X.pred)
dgp.pred <- sin(2.5*X.pred.dgp)
newdata.dgp <- data.frame(X=X.pred.dgp)
newdata <- data.frame(X=X.pred)

fitted.array.dgp <- array(NA,dim=c(length(n.vec),M,length(X.pred)))
fitted.array <- array(NA,dim=c(length(n.vec),M,length(X.pred)))

for(j in 1:length(n.vec)) {
  print(n.vec[j])  
  for(i in 1:M) {
    X <- sort(rbinom(n.vec[j],n.trials,.5))
    dgp <- sin(2.5*X)
    Y <- dgp + rnorm(n.vec[j],sd=sd(dgp))
    ghat.dgp <- lm(Y~sin(2.5*X))
    fitted.array.dgp[j,i,] <- predict(ghat.dgp,newdata=newdata.dgp)
    ghat.nw <- npreg(Y~ordered(X,levels=0:n.trials))
    fitted.array[j,i,] <- predict(ghat.nw,newdata=newdata)
  }
}

## Compute pointwise MSE at each support point

mse.dgp <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))
mse <- matrix(NA,nrow=length(n.vec),ncol=length(X.pred))

for(j in 1:length(n.vec)) {
  mse.dgp[j,] <- colMeans(sweep(fitted.array.dgp[j,,],2,dgp.pred)^2)
  mse[j,] <- colMeans(sweep(fitted.array[j,,],2,dgp.pred)^2)
}

mse.dgp.pointwise <- numeric()
mse.pointwise <- numeric()

for(i in 1:length(X.pred)) {
  mse.dgp.pointwise[i] <- coef(ltsReg(log(mse.dgp[,i])~log(n.vec)))[2]
  mse.pointwise[i] <- coef(ltsReg(log(mse[,i])~log(n.vec)))[2]
}

ylim <- range(c(mse.dgp.pointwise,mse.pointwise))

plot(X.pred.dgp,mse.dgp.pointwise,main="Rate of Convergence",ylim=ylim,xlab="X",ylab="MSE",type="b")
lines(X.pred.dgp,mse.pointwise,xlab="X",ylab="MSE",type="b",col="red")
legend("topleft",legend=c("DGP","NW"),col=c("black","red"),lty=1,bty="n")

foo <- data.frame(X.pred,mse.dgp.pointwise,mse.pointwise,mse.pointwise/mse.dgp.pointwise)
colnames(foo) <- c("X","Oracle","NW","ratio")
knitr::kable(foo,digits=2,align="rlll")
